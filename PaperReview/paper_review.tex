\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Paper Review 8DM50}

\author{\IEEEauthorblockN{Sander Derwig}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{Manon van Erp}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{Rutger Hendrix}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
\and
\IEEEauthorblockN{Dirk Loeffen}
\IEEEauthorblockA{\textit{IMAG/e} \\
\textit{Eindhoven Technical University} \\
s1252399 \\
d.w.m.loeffen@student.tue.nl}
\and
\IEEEauthorblockN{Djennifer Madzia-Madzou}
\IEEEauthorblockA{\textit{dept. name of organization (of Aff.)} \\
\textit{name of organization (of Aff.)}\\
City, Country \\
email address or ORCID}
}

\maketitle

%\begin{abstract}

%\end{abstract}

%\begin{IEEEkeywords}
%component, formatting, style, styling, insert
%\end{IEEEkeywords}

\section{Application Domain (81)}
One of the limitations of the resolution of magnetic resonance (MR) imaging is
acquisition time. Acquisition time has to be limited in order for MR imaging
remain convenient for patients. To increase resolution without increasing
acquisition time, one could try one of several super-resolution (SR) techniques.
A more recent technique to reach super-resolution is deep learning. The reviewed
paper demonstrates two super resolution networks. 1) A one-level non-progressive
neural network and 2) two-level progressive neural network.

\section{Methods (295)}
%Given the high resolution (HR) image $I_{\text{HR}}$ a mapping $f$ can be found
%such that the low resolution (LR) image $I_{\text{LR}}$ is obtained as in
%Eq.~\ref{eq:mapping}.
%\begin{equation}
%I_{\text{LR}} = f\left( I_{\text{HR}} \right) =
%\varphi\left(I_{\text{HR}}\right) + \epsilon
%\label{eq:mapping}
%\end{equation}
%In this equation, $\varphi$ is a down-sampling function and $\epsilon$ is the system noise.
To train the neural networks they have to be fed low resolution (LR) images. The
(LR) images are acquired by down-sampling and zero-filling the high resolution
(HR) images in Fourier space. By doing so in Fourier space, the image size is
unchanged but the image quality is degraded.

The first of the two networks is the one-level non-progressive neural network.
This network is a general adversarial network (GAN), thus it consists of a
generator and a discriminator. The generator consists of an encoder which has
eight sequential convolutional layers, each of which is followed by a rectified
linear unit (ReLu). The generator also consists of a reference feature
extraction network.

In the reviewed paper, four loss functions are used:
\begin{enumerate}
    \item The adversarial loss in the generative adversarial network framework is
    used to train the generator.
    \item The Mean-Squared Error evaluates the difference between the output of the
    generator and the corresponding ground truth at pixel-wise level. It can
    greatly improve the signal-to-noise ratio of generated images.
    \item The perceptual loss overcomes the problem that some details may be lost
    due to over-smoothed SR results. The perceptual loss recovers more details
    by measuring image similarity in a high-level feature space.
    \item The texture matching loss contributes to generate an image with great
    similarity between the output of the generator and the ground truth by
    statistically matching extracted features.
\end{enumerate}

Section 5 is about the two-level progressive network. The proposed network
sequentially up-samples the image in small steps, resulting in a large
up-sampling factor.

The image quality evaluation metrics that are used in this paper are structural
similarity, peak signal-to-noise ratio and information fidelity criterion.

\section{Discussion (179)}
One common problem in training a Generative Adversarial Network is that it is
highly unstable. This is inherently the case since often the generator and the
discriminator are trained simultaneously while competing against each other. In
the aforementioned paper the discriminator was trained four times before the
generator was trained once. This might help stabilize the model.

Another strong point of the methodology is the use of multiple loss functions.
Each loss function has its own (dis)advantages. By using the four loss
functions, the power of each one is combined and results in a generally better
applicable loss function for this application.

Using peak signal-to-noise ratio as a metric is sometimes problematic, since a
higher PSNR usually indicates a reconstruction of higher quality, but this is
not guaranteed. PSNR is also proven to be outperformed by most other popular
evaluation metrics, so the use of PSNR does not seem necessary in this paper.
But on the other hand it is beneficial to use multiple evaluation metrics to
ensure that the model is working optimally and correctly.

\section{Recommendations (216)}
Although MSE leads to a high signal-to-noise ratio in reference to the ground
truth, it tends to produce over-smoothed SR results. Therefore they also use
perceptual loss. Is there a way to combine these two to avoid one problem being
created that has to be solved with another loss function.

Also two distorted images with the same MSE may have very different types of
errors, some of which are much more visible than others. One error might be
preferred over the other, which is now not addressed with the use of MSE.

PSNR is no longer regarded as a reliable indicator of image quality degradation
[1]. Although a higher PSNR generally indicates that the reconstruction is of
higher quality, in some cases it may not. Bear in mind that none of these
objective measures are particularly good at predicting human visual response to
image quality. Sometimes PSNRs vary wildly between two almost indistinguishable
images. SSIM is recommended. So since this is already used we propose just
skipping PSNR.

The Cognitive Interaction Problem. It is widely known that cognitive
understanding and interactive visual processing (e.g., eye movements) influence
the perceived quality of images. For example, a human observer will give
different quality scores to the same image if given different instructions~\cite{b1}.

\begin{thebibliography}{00}
\bibitem{b1} Wang, Z., Bovik, A. C., Sheikh, H. R., & Simoncelli, E. P. (2004).
  Image quality assessment: from error visibility to structural similarity. IEEE
  transactions on image processing, 13(4), 600-612.

\end{thebibliography}

\end{document}
